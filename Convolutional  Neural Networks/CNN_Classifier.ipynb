{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задача классификации изображений"
      ],
      "metadata": {
        "id": "QAaRbw5Rvb8i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZRu-Qap7vWuJ"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(32,),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "train_size = int(len(dataset) * 0.6)\n",
        "val_size = int(len(dataset) * 0.2)\n",
        "test_size = len(dataset) - (val_size + train_size)\n",
        "\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=generator)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=8)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8)"
      ],
      "metadata": {
        "id": "gROtNe4RvwrD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 128, kernel_size=3, padding=1, stride=1)\n",
        "        self.conv2 = nn.Conv2d(128, 64, kernel_size=3, padding=1, stride=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 16 * 16, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "YdCyseDZycQH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNClassifier().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "patience = 2\n",
        "best_val_loss = float(\"inf\")\n",
        "patience_counter = 0\n",
        "model_path = \"best_cnn_classification.pth\"\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct_train = 0\n",
        "  total_train = 0\n",
        "\n",
        "  for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "    correct_train += (preds == labels).sum().item()\n",
        "    total_train += labels.size(0)\n",
        "\n",
        "  train_loss = running_loss /  len(train_loader)\n",
        "  train_accuracy = correct_train / total_train\n",
        "\n",
        "  model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct_val = 0\n",
        "  total_val = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_loss += loss.item()\n",
        "\n",
        "      preds = torch.argmax(outputs, dim=1)\n",
        "      correct_val += (preds == labels).sum().item()\n",
        "      total_val += labels.size(0)\n",
        "\n",
        "  val_loss /= len(val_loader)\n",
        "  val_accuracy = correct_val / total_val\n",
        "\n",
        "\n",
        "  print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "  if val_loss < best_val_loss:\n",
        "    best_val_loss = val_loss\n",
        "    patience_counter = 0\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"✔ Model improved. Saved to {model_path}\")\n",
        "  else:\n",
        "    patience_counter += 1\n",
        "    if patience_counter >= patience:\n",
        "      print(\"Ранняя остановка сработала!\")\n",
        "      break\n",
        "\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)\n",
        "print(f\"✅ Best model loaded from {model_path}\")\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    test_loss += loss.item()\n",
        "\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "    correct_test += (preds == labels).sum().item()\n",
        "    total_test += labels.size(0)\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = correct_test / total_test\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHf0BIK00r9v",
        "outputId": "d715a9a3-befb-4948-b2b1-a67e6e853579"
      },
      "execution_count": 33,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5: 100%|██████████| 469/469 [06:38<00:00,  1.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 1.8712, Val Loss: 1.4935\n",
            "✔ Model improved. Saved to best_cnn_classification.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5: 100%|██████████| 469/469 [06:33<00:00,  1.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Train Loss: 1.6515, Val Loss: 1.4145\n",
            "✔ Model improved. Saved to best_cnn_classification.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5: 100%|██████████| 469/469 [06:34<00:00,  1.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Train Loss: 1.5663, Val Loss: 1.3325\n",
            "✔ Model improved. Saved to best_cnn_classification.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/5: 100%|██████████| 469/469 [06:33<00:00,  1.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Train Loss: 1.4995, Val Loss: 1.2733\n",
            "✔ Model improved. Saved to best_cnn_classification.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 469/469 [06:33<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 1.4431, Val Loss: 1.2279\n",
            "✔ Model improved. Saved to best_cnn_classification.pth\n",
            "✅ Best model loaded from best_cnn_classification.pth\n",
            "Test Loss: 1.2093, Test Accuracy: 0.5877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"best_cnn_classification.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "j-6KQjuW1wnt",
        "outputId": "630b71c1-23a5-4160-a847-91dd0f32ec3a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_c1ca385f-8cb5-4be9-9add-bb57c894c491\", \"best_cnn_classification.pth\", 2411520)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}