{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bba92138-3d01-4574-8d6b-51d84d036817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dada2544-1ac9-4032-8af4-90f0ed8d3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "\n",
    "dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "trainset, valset, testset = random_split(dataset, [train_size, val_size, test_size],\n",
    "                                         generator=g)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdc148ef-3426-425d-bc14-fa42184a7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int = 32 * 32 * 3,\n",
    "                 hidden_dim: int = 128, output_dim: int = 10\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5c7a7a4-64ec-48fb-be58-c31194c9f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        device,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        epochs: int = 1,\n",
    "        save_weights: bool =True,\n",
    "        log_dir: str = \"runs\"\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.epoch = 1\n",
    "\n",
    "        self.save_weights = save_weights\n",
    "\n",
    "        self.current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        self.model_name = self.model.__class__.__name__\n",
    "        self.log_dir = os.path.join(\"runs\", f\"{self.model_name}_PerceptronClf_{self.current_time}\")\n",
    "\n",
    "        self.writer = SummaryWriter(log_dir=self.log_dir)\n",
    "\n",
    "        self.schedular = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=0.5,\n",
    "            patience=2\n",
    "        )\n",
    "        \n",
    "    def process_model(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, train_accuracy = self._train_model()\n",
    "            val_loss, val_accuracy = self._validate_model()\n",
    "\n",
    "            self.schedular.step(val_loss)\n",
    "            \n",
    "            self.epoch += 1\n",
    "\n",
    "        self.writer.close()\n",
    "        return train_loss, val_loss, train_accuracy, val_accuracy\n",
    "\n",
    "    def _train_model(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        all_preds, all_targets = [], []\n",
    "\n",
    "        for images, labels in tqdm(self.train_loader):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss = total_loss / len(self.train_loader)\n",
    "        accuracy = accuracy_score(all_targets, all_preds)\n",
    "        precision = precision_score(all_targets, all_preds, average=\"weighted\", zero_division=0)\n",
    "        f1 = f1_score(all_targets, all_preds, average=\"weighted\", zero_division=0)\n",
    "        \n",
    "        self._print_metrics(\"Train\", train_loss, accuracy, precision, f1)\n",
    "        \n",
    "        self.writer.add_scalar(\"Loss/Train\", train_loss, self.epoch)\n",
    "        self.writer.add_scalar(\"Accuracy/Train\", accuracy, self.epoch)\n",
    "        self.writer.add_scalar(\"Precision/Train\", precision, self.epoch)\n",
    "        self.writer.add_scalar(\"F1/Train\", f1, self.epoch)\n",
    "\n",
    "        return train_loss, accuracy\n",
    "\n",
    "    def _validate_model(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        all_preds, all_targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(self.val_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "        val_loss = total_loss / len(self.val_loader)\n",
    "        accuracy = accuracy_score(all_targets, all_preds)\n",
    "        precision = precision_score(all_targets, all_preds, average=\"weighted\", zero_division=0)\n",
    "        f1 = f1_score(all_targets, all_preds, average=\"weighted\", zero_division=0)\n",
    "        \n",
    "        self._print_metrics(\"Val\", val_loss, accuracy, precision, f1)\n",
    "        \n",
    "        self.writer.add_scalar(\"Loss/Val\", val_loss, self.epoch)\n",
    "        self.writer.add_scalar(\"Accuracy/Val\", accuracy, self.epoch)\n",
    "        self.writer.add_scalar(\"Precision/Val\", precision, self.epoch)\n",
    "        self.writer.add_scalar(\"F1/Val\", f1, self.epoch)\n",
    "\n",
    "        return val_loss, accuracy\n",
    "\n",
    "    def test_model(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        all_preds, all_targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(self.test_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(labels.cpu().numpy())\n",
    "                \n",
    "        test_loss = total_loss / len(self.test_loader)\n",
    "        accuracy = accuracy_score(all_targets, all_preds)\n",
    "        precision = precision_score(all_targets, all_preds, average=\"weighted\", zero_division=0)\n",
    "        f1 = f1_score(all_targets, all_preds, average=\"weighted\", zero_division=0)\n",
    "        \n",
    "        self._print_metrics(\"Test\", test_loss, accuracy, precision, f1)\n",
    "\n",
    "        if self.save_weights:\n",
    "            torch.save(self.model.state_dict(), 'densora_gru_weights.pth')\n",
    "\n",
    "        return test_loss, accuracy\n",
    "\n",
    "    def _print_metrics(self, phase: str, loss, accuracy, precision, f1):\n",
    "        if phase == \"Test\":\n",
    "            print(f\"{phase} Loss {self.epoch - 1}: {loss:.4f} | Accuracy: {accuracy:.4f}\")\n",
    "        else:\n",
    "            print(f\"{phase} Loss {self.epoch}: {loss:.4f} | Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"F1 score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b8b2513-6e23-443e-9c84-2d3e43259605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:06<00:00, 70.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 1: 2.2265 | Accuracy: 0.2072\n",
      "Precision: 0.1802\n",
      "F1 score: 0.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 113.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss 1: 2.1698 | Accuracy: 0.2308\n",
      "Precision: 0.2248\n",
      "F1 score: 0.1548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:04<00:00, 110.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 2: 2.1293 | Accuracy: 0.2604\n",
      "Precision: 0.2374\n",
      "F1 score: 0.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 124.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss 2: 2.0982 | Accuracy: 0.2817\n",
      "Precision: 0.2692\n",
      "F1 score: 0.2356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:04<00:00, 111.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 3: 2.0714 | Accuracy: 0.2852\n",
      "Precision: 0.2655\n",
      "F1 score: 0.2387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 123.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss 3: 2.0352 | Accuracy: 0.2924\n",
      "Precision: 0.2873\n",
      "F1 score: 0.2588\n",
      "Final Train Loss: 2.0714, Val Loss: 2.0352\n",
      "Final Train Acc: 0.2852, Val Acc: 0.2924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 3: 2.0363 | Accuracy: 0.2961\n",
      "Precision: 0.2916\n",
      "F1 score: 0.2631\n",
      "Test Loss: 2.0363, Test Accuracy: 0.2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=3,   \n",
    "    save_weights=False\n",
    ")\n",
    "\n",
    "train_loss, val_loss, train_acc, val_acc = trainer.process_model()\n",
    "print(f\"Final Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "print(f\"Final Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "test_loss, test_acc = trainer.test_model()\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "740bd8d0-85a6-48dc-8f17-674711f85720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/Train', 'Accuracy/Train', 'Precision/Train', 'F1/Train', 'Loss/Val', 'Accuracy/Val', 'Precision/Val', 'F1/Val'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
      "[ScalarEvent(wall_time=1755755038.138462, step=1, value=2.2264561653137207), ScalarEvent(wall_time=1755755043.8927855, step=2, value=2.12925386428833), ScalarEvent(wall_time=1755755049.4660344, step=3, value=2.0714430809020996)]\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "ea = event_accumulator.EventAccumulator(\"runs/Perceptron_PerceptronClf_2025-08-21_08-43-51\")\n",
    "ea.Reload()\n",
    "\n",
    "print(ea.Tags())  # должно показать: 'scalars'\n",
    "print(ea.Scalars('Loss/Train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7967a08-51b3-4c2a-993d-43c48121a525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
