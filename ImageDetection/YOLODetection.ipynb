{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e55b1c28-ddb6-4cba-836a-1dd3d072626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import VOCDetection\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2a1753e-2746-449c-aba6-57724b99ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARDataset(Dataset):\n",
    "    def __init__(self, root, train=True, S=7, transform=None, download=True):\n",
    "        self.dataset = CIFAR10(root=root, train=train, transform=transform, download=download)\n",
    "        self.S = S\n",
    "        self.classes = self.dataset.classes\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "\n",
    "        x_center = 0.5\n",
    "        y_center = 0.5\n",
    "        bw = 1.0\n",
    "        bh = 1.0\n",
    "\n",
    "        target_tensor = torch.zeros(self.S, self.S, 5 + len(self.classes))\n",
    "        i = int(y_center * self.S)\n",
    "        j = int(x_center * self.S)\n",
    "        target_tensor[i, j, 0:4] = torch.tensor([x_center, y_center, bw, bh])\n",
    "        target_tensor[i, j, 4] = 1\n",
    "        target_tensor[i, j, 5 + label] = 1\n",
    "\n",
    "        return img, target_tensor   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5045ac0f-650a-4eb9-b2b2-19a4d0cac0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CIFARDataset(root='./data', train=True, S=7, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e498fe9e-2601-4396-a5b8-0a49fb8284a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOModel(nn.Module):\n",
    "    def __init__(self, S: int = 7, B: int = 1, C: int = 10):\n",
    "        super().__init__()\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), # 16x16 -> 16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), # 8x8 -> 8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1), # 4x4\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((S, S))\n",
    "        )\n",
    "\n",
    "        self.pred = nn.Conv2d(256, B * (5 + C), kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pred(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "356d8643-817a-42a9-956b-93a332e138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOLoss(nn.Module):\n",
    "    def __init__(self, S=7, B=1, C=10, lambda_coord=5, lambda_noobj=0.5):\n",
    "        super().__init__()\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        obj_mask = target[..., 4] == 1\n",
    "\n",
    "        coord_loss = F.mse_loss(predictions[obj_mask][..., 0:2], target[obj_mask][..., 0:2], reduction='sum') + \\\n",
    "                     F.mse_loss(predictions[obj_mask][..., 2:4], target[obj_mask][..., 2:4], reduction='sum')\n",
    "\n",
    "        obj_loss = F.binary_cross_entropy_with_logits(predictions[..., 4], target[..., 4], reduction='sum')\n",
    "\n",
    "        class_loss = F.cross_entropy(predictions[obj_mask][..., 5:], \n",
    "                                     target[obj_mask][..., 5:].argmax(dim=-1), reduction='sum') \\\n",
    "                     if obj_mask.any() else torch.tensor(0.0, device=predictions.device)\n",
    "\n",
    "        loss = self.lambda_coord * coord_loss + obj_loss + class_loss\n",
    "        return loss / predictions.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db5fd6fe-56cd-4bde-8035-ff4167095cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(bbox1, bbox2):\n",
    "    b1_x1 = box1[..., 0] - box1[..., 2] / 2\n",
    "    b1_y1 = box1[..., 1] - box1[..., 3] / 2\n",
    "    b1_x2 = box1[..., 0] + box1[..., 2] / 2\n",
    "    b1_y2 = box1[..., 1] + box1[..., 3] / 2\n",
    "\n",
    "    b2_x1 = box2[..., 0] - box2[..., 2] / 2\n",
    "    b2_y1 = box2[..., 1] - box2[..., 3] / 2\n",
    "    b2_x2 = box2[..., 0] + box2[..., 2] / 2\n",
    "    b2_y2 = box2[..., 1] + box2[..., 3] / 2\n",
    "\n",
    "    inter_x1 = torch.max(b1_x1, b2_x1)\n",
    "    inter_y1 = torch.max(b1_y1, b2_y1)\n",
    "    inter_x2 = torch.min(b1_x2, b2_x2)\n",
    "    inter_y2 = torch.min(b1_y2, b2_y2)\n",
    "\n",
    "    inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * \\\n",
    "                 torch.clamp(inter_y2 - inter_y1, min=0)\n",
    "\n",
    "    b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "    b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "\n",
    "    iou = inter_area / (b1_area + b2_area - inter_area + 1e-6)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0723b0-d5af-4e07-bfb6-5e2915738724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 12500/12500 [35:33<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Loss: 2.7718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▍                                                                      | 590/12500 [01:32<31:37,  6.28it/s]"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = YOLOModel(S=7, B=1, C=10).to(device)\n",
    "criterion = YOLOLoss(S=7, B=1, C=10)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, targets in tqdm(train_loader):\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92791e-4fda-4bfa-b904-2c464d88d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "ious = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, targets in DataLoader(train_dataset, batch_size=32, shuffle=False):\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        preds = model(imgs)\n",
    "\n",
    "        pred_obj = torch.sigmoid(preds[..., 4])\n",
    "        best_cell = pred_obj.view(imgs.size(0), -1).argmax(dim=1)\n",
    "\n",
    "        for i in range(imgs.size(0)):\n",
    "            row = best_cell[i] // preds.size(2)\n",
    "            col = best_cell[i] % preds.size(2)\n",
    "\n",
    "            pred_box = preds[i, row, col, 0:4]\n",
    "            true_box = targets[i, row, col, 0:4]\n",
    "\n",
    "            iou = bbox_iou(pred_box.unsqueeze(0), true_box.unsqueeze(0))\n",
    "            ious.append(iou.item())\n",
    "\n",
    "            pred_class = preds[i, row, col, 5:].argmax()\n",
    "            true_class = targets[i, row, col, 5:].argmax()\n",
    "\n",
    "            correct += int(pred_class == true_class)\n",
    "            total += 1\n",
    "\n",
    "print(f\"Mean IoU: {sum(ious)/len(ious):.4f}\")\n",
    "print(f\"Classification Accuracy: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe5458-a4ae-46ad-942a-13fb8e1a58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_transform = T.ToPILImage()\n",
    "\n",
    "def show_predictions(model, dataset, num_images=5):\n",
    "    model.eval()\n",
    "    fig, axs = plt.subplots(1, num_images, figsize=(15, 4))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        img, target = dataset[i]\n",
    "        img_tensor = img.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(img_tensor)\n",
    "\n",
    "        pred = pred.squeeze(0)  # (S, S, 5+C)\n",
    "        pred_obj = torch.sigmoid(pred[..., 4])\n",
    "        best_idx = pred_obj.view(-1).argmax()\n",
    "\n",
    "        row = best_idx // pred.size(0)\n",
    "        col = best_idx % pred.size(1)\n",
    "\n",
    "        pred_box = pred[row, col, 0:4].cpu()\n",
    "        pred_class = pred[row, col, 5:].argmax().item()\n",
    "\n",
    "        true_box = target[row, col, 0:4]\n",
    "        true_class = target[row, col, 5:].argmax().item()\n",
    "\n",
    "        img_show = inv_transform(img.cpu())\n",
    "        axs[i].imshow(img_show)\n",
    "\n",
    "        def draw_box(ax, box, color, label):\n",
    "            x, y, w, h = box\n",
    "            H, W = img_show.size[1], img_show.size[0]\n",
    "            x1 = (x - w/2) * W\n",
    "            y1 = (y - h/2) * H\n",
    "            rect = plt.Rectangle((x1, y1), w*W, h*H, \n",
    "                                 fill=False, color=color, linewidth=2)\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x1, y1, label, color=color, fontsize=8, backgroundcolor=\"white\")\n",
    "\n",
    "        draw_box(axs[i], true_box, \"green\", dataset.classes[true_class])\n",
    "        draw_box(axs[i], pred_box, \"red\", dataset.classes[pred_class])\n",
    "\n",
    "        axs[i].axis(\"off\")\n",
    "        axs[i].set_title(f\"GT: {dataset.classes[true_class]}\\nPred: {dataset.classes[pred_class]}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(model, test_dataset, num_images=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
